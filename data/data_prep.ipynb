{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d6784e",
   "metadata": {},
   "source": [
    "# Multimodal Hate Speech Detection - DATASET\n",
    "\n",
    "\n",
    "\n",
    "This notebook contains data analysis and testing for the Arabic multimodal hate speech detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d055e",
   "metadata": {},
   "source": [
    "## 1. Download Data\n",
    "\n",
    "Download and extract the Prop2Hate-Meme dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"QCRI/Prop2Hate-Meme\")\n",
    "\n",
    "# Specify the directory where you want to save the dataset\n",
    "\n",
    "output_dir=\"./Prop2Hate-Meme\"\n",
    "\n",
    "# Save the dataset to the specified directory. This will save all splits to the output directory.\n",
    "dataset.save_to_disk(output_dir)\n",
    "\n",
    "# If you want to get the raw images from HF dataset format\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory to save the images\n",
    "output_dir=\"./Prop2Hate-Meme/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the dataset and save each image\n",
    "for split in ['train','dev','test']:     \n",
    "    jsonl_path = os.path.join(output_dir, f\"arabic_hateful_meme_{split}.jsonl\")\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, item in enumerate(dataset[split]):\n",
    "            # Access the image directly as it's already a PIL.Image object\n",
    "            image = item['image']\n",
    "            image_path = os.path.join(output_dir, item['img_path'])\n",
    "            # Ensure the directory exists\n",
    "            os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
    "            image.save(image_path)\n",
    "            del item['image']\n",
    "            del item['prop_label']\n",
    "            del item['hate_fine_grained_label']\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa13257",
   "metadata": {},
   "source": [
    "## 2. Checking Data Splits Balance\n",
    "\n",
    "Analyze the distribution of hate/non-hate labels across train, dev, and test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb182ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def count_labels(file_path):\n",
    "    hate = 0\n",
    "    non_hate = 0\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sample = json.loads(line)\n",
    "            label = sample.get(\"hate_label\")\n",
    "            if label == 1:\n",
    "                hate += 1\n",
    "            elif label == 0:\n",
    "                non_hate += 1\n",
    "    return hate, non_hate\n",
    "\n",
    "# Replace these with your actual file paths\n",
    "files = {\n",
    "    \"train\": \"Prop2Hate-Meme/arabic_hateful_meme_train.jsonl\",\n",
    "    \"dev\": \"Prop2Hate-Meme/arabic_hateful_meme_dev.jsonl\",\n",
    "    \"test\": \"Prop2Hate-Meme/arabic_hateful_meme_test.jsonl\"\n",
    "}\n",
    "\n",
    "for split, path in files.items():\n",
    "    hate, non_hate = count_labels(path)\n",
    "    total = hate + non_hate\n",
    "    print(f\"{split.upper()} â€” Total: {total}, Hate: {hate}, Non-Hate: {non_hate}, Hate %: {hate / total:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d4c1d",
   "metadata": {},
   "source": [
    "## 3. Test on Gold Test Split\n",
    "\n",
    "Load trained models and evaluate on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # Load gold labels and predictions\n",
    "gold = pd.read_csv(\"task3_test_gold.csv\")            # columns: id,label\n",
    "pred1 = pd.read_csv(\"../scripts/prediction0_7333.csv\") \n",
    "\n",
    "# align by id\n",
    "df = gold.merge(pred1, on=\"id\")\n",
    "print(\"Check\",df.head())\n",
    "# get lists\n",
    "y_true = df[\"testing_label\"].tolist()\n",
    "y_pred = df[\"prediction\"].tolist()\n",
    "\n",
    "# pick metrics\n",
    "print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred, pos_label=\"hate\"))\n",
    "print(\"Recall   :\", recall_score(y_true, y_pred, pos_label=\"hate\"))\n",
    "print(\"F1       :\", f1_score(y_true, y_pred, pos_label=\"hate\"))\n",
    "print(\"Macro F1 :\", f1_score(y_true, y_pred, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a9646",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-hate', 'Hate'], \n",
    "                yticklabels=['Non-hate', 'Hate'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# plot_confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
